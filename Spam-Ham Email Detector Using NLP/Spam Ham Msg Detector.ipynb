{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be90a1da",
   "metadata": {},
   "source": [
    "## SPAM HAM MESSAGE DETECTOR USING NLP AND ML\n",
    "It takes data as input and run its model to tell whether the data is spam msg or ham msg."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3ccf6",
   "metadata": {},
   "source": [
    "#### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab1526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c1e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data='Hello this is hitin yadav. Chill guys'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e08d1ac",
   "metadata": {},
   "source": [
    "#### CHECKING HOW WORD TOKENIZER AND SENTENCE TOKENIZER WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b5a7cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'this', 'is', 'hitin', 'yadav', '.', 'Chill', 'guys']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8911c5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello this is hitin yadav.', 'Chill guys']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020e344b",
   "metadata": {},
   "source": [
    "#### READING DATASET & RENAMING COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0249deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"SMSSpamCollection.tsv\",sep='\\t',header=None)\n",
    "df.columns=['target','phrase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d257b7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                             phrase\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481b1a1",
   "metadata": {},
   "source": [
    "#### CHECKING ANY NULL VALUES IN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7473acca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "phrase    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cff123",
   "metadata": {},
   "source": [
    "#### APPLYING WORD TOKENIZER TO PHRASE COLUMN\n",
    "Tokenizer is used for dividing a string of written language into its component words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efac1a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in df.phrase:\\n    print(nltk.word_tokenize(i))'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in df.phrase:\n",
    "    print(nltk.word_tokenize(i))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cf36aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in df.phrase:\n",
    "    l.append(nltk.word_tokenize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d09bdfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go',\n",
       " 'until',\n",
       " 'jurong',\n",
       " 'point',\n",
       " ',',\n",
       " 'crazy',\n",
       " '..',\n",
       " 'Available',\n",
       " 'only',\n",
       " 'in',\n",
       " 'bugis',\n",
       " 'n',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'e',\n",
       " 'buffet',\n",
       " '...',\n",
       " 'Cine',\n",
       " 'there',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat',\n",
       " '...']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bc9c8a",
   "metadata": {},
   "source": [
    "#### CREATING A NEW COLUMN TOKEN TO SAVE UPDATED TOKENIZE VALUES OF PHRASE COLUMN-- WHICH IS STORED IN LIST( l )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "136c8ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token']=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b19a3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>phrase</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[Ok, lar, ..., Joking, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                             phrase  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...   \n",
       "1    ham                      Ok lar... Joking wif u oni...   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3    ham  U dun say so early hor... U c already then say...   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                               token  \n",
       "0  [Go, until, jurong, point, ,, crazy, .., Avail...  \n",
       "1           [Ok, lar, ..., Joking, wif, u, oni, ...]  \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...  \n",
       "3  [U, dun, say, so, early, hor, ..., U, c, alrea...  \n",
       "4  [Nah, I, do, n't, think, he, goes, to, usf, ,,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9db04",
   "metadata": {},
   "source": [
    "#### IMPORTING PORTER STEMMER\n",
    "Stemming and Lemmatization are Text Normalization (or sometimes called Word Normalization).\n",
    "\n",
    "For example, searching for fish on Google will also result in fishes, fishing as fish is the stem of both words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b978b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97f738cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0708f5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('doing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "734c9efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, until, jurong, point, ,, crazy, .., Avail...\n",
       "1             [Ok, lar, ..., Joking, wif, u, oni, ...]\n",
       "2    [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
       "3    [U, dun, say, so, early, hor, ..., U, c, alrea...\n",
       "4    [Nah, I, do, n't, think, he, goes, to, usf, ,,...\n",
       "5    [FreeMsg, Hey, there, darling, it, 's, been, 3...\n",
       "Name: token, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.token[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77b70799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.phrase[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "897599a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go until jurong point, crazy.. available only in bugis n great world la e buffet... cine there got amore wat...'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(df.phrase[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d594cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in df.token:\n",
    "    l1=[]\n",
    "    for j in i:\n",
    "        l1.append(ps.stem(j))\n",
    "    l.append(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "478d9951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'until',\n",
       " 'jurong',\n",
       " 'point',\n",
       " ',',\n",
       " 'crazi',\n",
       " '..',\n",
       " 'avail',\n",
       " 'onli',\n",
       " 'in',\n",
       " 'bugi',\n",
       " 'n',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'e',\n",
       " 'buffet',\n",
       " '...',\n",
       " 'cine',\n",
       " 'there',\n",
       " 'got',\n",
       " 'amor',\n",
       " 'wat',\n",
       " '...']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b10b4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723c09d6",
   "metadata": {},
   "source": [
    "#### CREATING A NEW COLUMN STEM TO SAVE UPDATED STEMMED WORDS OF TOKEN COLUMN-- WHICH IS STORED IN LIST( l )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5eec7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stem']=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4d202e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>phrase</th>\n",
       "      <th>token</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "      <td>[go, until, jurong, point, ,, crazi, .., avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[Ok, lar, ..., Joking, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, earli, hor, ..., u, c, alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, ,, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                             phrase  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...   \n",
       "1    ham                      Ok lar... Joking wif u oni...   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3    ham  U dun say so early hor... U c already then say...   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                               token  \\\n",
       "0  [Go, until, jurong, point, ,, crazy, .., Avail...   \n",
       "1           [Ok, lar, ..., Joking, wif, u, oni, ...]   \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  [U, dun, say, so, early, hor, ..., U, c, alrea...   \n",
       "4  [Nah, I, do, n't, think, he, goes, to, usf, ,,...   \n",
       "\n",
       "                                                stem  \n",
       "0  [go, until, jurong, point, ,, crazi, .., avail...  \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]  \n",
       "2  [free, entri, in, 2, a, wkli, comp, to, win, f...  \n",
       "3  [u, dun, say, so, earli, hor, ..., u, c, alrea...  \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, ,, ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132ab378",
   "metadata": {},
   "source": [
    "#### IMPORTING WORD NET LEMMATIZER\n",
    "Lemmatization gorups togethor different inflected form of words, somehow similar to stemming, as it maps several words into one common root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af03d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c40040e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4877d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.lemmatize('was',pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef6fbd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in df.stem:\n",
    "    l2=[]\n",
    "    for j in i:\n",
    "        l2.append(wl.lemmatize(j,pos='v'))   # here pos refer to part of speech which we have used verb ('v') as tag\n",
    "    l.append(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0d3b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lem']=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac17fce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>phrase</th>\n",
       "      <th>token</th>\n",
       "      <th>stem</th>\n",
       "      <th>lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "      <td>[go, until, jurong, point, ,, crazi, .., avail...</td>\n",
       "      <td>[go, until, jurong, point, ,, crazi, .., avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[Ok, lar, ..., Joking, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, earli, hor, ..., u, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, earli, hor, ..., u, c, alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, ,, ...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, ,, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                             phrase  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...   \n",
       "1    ham                      Ok lar... Joking wif u oni...   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3    ham  U dun say so early hor... U c already then say...   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                               token  \\\n",
       "0  [Go, until, jurong, point, ,, crazy, .., Avail...   \n",
       "1           [Ok, lar, ..., Joking, wif, u, oni, ...]   \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  [U, dun, say, so, early, hor, ..., U, c, alrea...   \n",
       "4  [Nah, I, do, n't, think, he, goes, to, usf, ,,...   \n",
       "\n",
       "                                                stem  \\\n",
       "0  [go, until, jurong, point, ,, crazi, .., avail...   \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]   \n",
       "2  [free, entri, in, 2, a, wkli, comp, to, win, f...   \n",
       "3  [u, dun, say, so, earli, hor, ..., u, c, alrea...   \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, ,, ...   \n",
       "\n",
       "                                                 lem  \n",
       "0  [go, until, jurong, point, ,, crazi, .., avail...  \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]  \n",
       "2  [free, entri, in, 2, a, wkli, comp, to, win, f...  \n",
       "3  [u, dun, say, so, earli, hor, ..., u, c, alrea...  \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, ,, ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a33b7",
   "metadata": {},
   "source": [
    "#### IMPORTING PUNCTUATION FROM STRING\n",
    "We will remove all punctuation marks form the dataset so that we can remove all uncessary unimportant words from our datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1c553d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d8199df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this way we are creating a list so we can add more things in list\n",
    "# which we want to get removed from the data other than punctautions\n",
    "\n",
    "a=[]\n",
    "for i in string.punctuation:\n",
    "    a.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83bd1320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '\"', '#', '$', '%']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "536e2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in df.lem:\n",
    "    l2=[]\n",
    "    for j in i:\n",
    "        if j not in a:\n",
    "            l2.append(j)\n",
    "    l.append(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44bdc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['punc']=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74af4a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>phrase</th>\n",
       "      <th>token</th>\n",
       "      <th>stem</th>\n",
       "      <th>lem</th>\n",
       "      <th>punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "      <td>[go, until, jurong, point, ,, crazi, .., avail...</td>\n",
       "      <td>[go, until, jurong, point, ,, crazi, .., avail...</td>\n",
       "      <td>[go, until, jurong, point, crazi, .., avail, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[Ok, lar, ..., Joking, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, earli, hor, ..., u, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, earli, hor, ..., u, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, earli, hor, ..., u, c, alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, ,, ...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, ,, ...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, he,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                             phrase  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...   \n",
       "1    ham                      Ok lar... Joking wif u oni...   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3    ham  U dun say so early hor... U c already then say...   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                               token  \\\n",
       "0  [Go, until, jurong, point, ,, crazy, .., Avail...   \n",
       "1           [Ok, lar, ..., Joking, wif, u, oni, ...]   \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  [U, dun, say, so, early, hor, ..., U, c, alrea...   \n",
       "4  [Nah, I, do, n't, think, he, goes, to, usf, ,,...   \n",
       "\n",
       "                                                stem  \\\n",
       "0  [go, until, jurong, point, ,, crazi, .., avail...   \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]   \n",
       "2  [free, entri, in, 2, a, wkli, comp, to, win, f...   \n",
       "3  [u, dun, say, so, earli, hor, ..., u, c, alrea...   \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, ,, ...   \n",
       "\n",
       "                                                 lem  \\\n",
       "0  [go, until, jurong, point, ,, crazi, .., avail...   \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]   \n",
       "2  [free, entri, in, 2, a, wkli, comp, to, win, f...   \n",
       "3  [u, dun, say, so, earli, hor, ..., u, c, alrea...   \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, ,, ...   \n",
       "\n",
       "                                                punc  \n",
       "0  [go, until, jurong, point, crazi, .., avail, o...  \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]  \n",
       "2  [free, entri, in, 2, a, wkli, comp, to, win, f...  \n",
       "3  [u, dun, say, so, earli, hor, ..., u, c, alrea...  \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, he,...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a953e7",
   "metadata": {},
   "source": [
    "#### IMORTING STOP WORDS\n",
    "Stop words are words which are filtered out before or after processing of text. When applying machine learning to text, these words can add a lot of noise. That’s why we want to remove these irrelevant words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef3bf3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9ed2845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=stopwords.words('english')\n",
    "b[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6deb6850",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in df.punc:\n",
    "    l2=[]\n",
    "    for j in i:\n",
    "        if j not in b:\n",
    "            l2.append(j)\n",
    "    l.append(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fed87ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stopword']=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4542a72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>phrase</th>\n",
       "      <th>token</th>\n",
       "      <th>stem</th>\n",
       "      <th>lem</th>\n",
       "      <th>punc</th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "      <td>[go, until, jurong, point, ,, crazi, .., avail...</td>\n",
       "      <td>[go, until, jurong, point, ,, crazi, .., avail...</td>\n",
       "      <td>[go, until, jurong, point, crazi, .., avail, o...</td>\n",
       "      <td>[go, jurong, point, crazi, .., avail, onli, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[Ok, lar, ..., Joking, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, earli, hor, ..., u, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, earli, hor, ..., u, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, earli, hor, ..., u, c, alrea...</td>\n",
       "      <td>[u, dun, say, earli, hor, ..., u, c, alreadi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, ,, ...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, ,, ...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, he,...</td>\n",
       "      <td>[nah, n't, think, goe, usf, live, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                             phrase  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...   \n",
       "1    ham                      Ok lar... Joking wif u oni...   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3    ham  U dun say so early hor... U c already then say...   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                               token  \\\n",
       "0  [Go, until, jurong, point, ,, crazy, .., Avail...   \n",
       "1           [Ok, lar, ..., Joking, wif, u, oni, ...]   \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  [U, dun, say, so, early, hor, ..., U, c, alrea...   \n",
       "4  [Nah, I, do, n't, think, he, goes, to, usf, ,,...   \n",
       "\n",
       "                                                stem  \\\n",
       "0  [go, until, jurong, point, ,, crazi, .., avail...   \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]   \n",
       "2  [free, entri, in, 2, a, wkli, comp, to, win, f...   \n",
       "3  [u, dun, say, so, earli, hor, ..., u, c, alrea...   \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, ,, ...   \n",
       "\n",
       "                                                 lem  \\\n",
       "0  [go, until, jurong, point, ,, crazi, .., avail...   \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]   \n",
       "2  [free, entri, in, 2, a, wkli, comp, to, win, f...   \n",
       "3  [u, dun, say, so, earli, hor, ..., u, c, alrea...   \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, ,, ...   \n",
       "\n",
       "                                                punc  \\\n",
       "0  [go, until, jurong, point, crazi, .., avail, o...   \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]   \n",
       "2  [free, entri, in, 2, a, wkli, comp, to, win, f...   \n",
       "3  [u, dun, say, so, earli, hor, ..., u, c, alrea...   \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, he,...   \n",
       "\n",
       "                                            stopword  \n",
       "0  [go, jurong, point, crazi, .., avail, onli, bu...  \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]  \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
       "3  [u, dun, say, earli, hor, ..., u, c, alreadi, ...  \n",
       "4  [nah, n't, think, goe, usf, live, around, though]  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4dd43688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [go, jurong, point, crazi, .., avail, onli, bu...\n",
       "1               [ok, lar, ..., joke, wif, u, oni, ...]\n",
       "2    [free, entri, 2, wkli, comp, win, fa, cup, fin...\n",
       "3    [u, dun, say, earli, hor, ..., u, c, alreadi, ...\n",
       "4    [nah, n't, think, goe, usf, live, around, though]\n",
       "Name: stopword, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stopword.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f0c9fa",
   "metadata": {},
   "source": [
    "#### USING JOIN FUNCTION\n",
    "We can see out stopword data is in the list form and we want to convert it back to its original form, removing list back to string. So we can use join function to join all the list with space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "627201db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(['a','b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a3ca141",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in df.stopword:\n",
    "    l.append(\" \".join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "550c9be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazi .. avail onli bugi n great world la e buffet ... cine get amor wat ...',\n",
       " 'ok lar ... joke wif u oni ...',\n",
       " \"free entri 2 wkli comp win fa cup final tkt 21st may 2005 text fa 87121 receiv entri question std txt rate c 's appli 08452810075over18 's\",\n",
       " 'u dun say earli hor ... u c alreadi say ...',\n",
       " \"nah n't think goe usf live around though\"]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c8eb2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ready']=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa356528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>phrase</th>\n",
       "      <th>token</th>\n",
       "      <th>stem</th>\n",
       "      <th>lem</th>\n",
       "      <th>punc</th>\n",
       "      <th>stopword</th>\n",
       "      <th>ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "      <td>[go, until, jurong, point, ,, crazi, .., avail...</td>\n",
       "      <td>[go, until, jurong, point, ,, crazi, .., avail...</td>\n",
       "      <td>[go, until, jurong, point, crazi, .., avail, o...</td>\n",
       "      <td>[go, jurong, point, crazi, .., avail, onli, bu...</td>\n",
       "      <td>go jurong point crazi .. avail onli bugi n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[Ok, lar, ..., Joking, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "      <td>ok lar ... joke wif u oni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, earli, hor, ..., u, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, earli, hor, ..., u, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, earli, hor, ..., u, c, alrea...</td>\n",
       "      <td>[u, dun, say, earli, hor, ..., u, c, alreadi, ...</td>\n",
       "      <td>u dun say earli hor ... u c alreadi say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, ,, ...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, ,, ...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, he,...</td>\n",
       "      <td>[nah, n't, think, goe, usf, live, around, though]</td>\n",
       "      <td>nah n't think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                             phrase  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...   \n",
       "1    ham                      Ok lar... Joking wif u oni...   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3    ham  U dun say so early hor... U c already then say...   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                               token  \\\n",
       "0  [Go, until, jurong, point, ,, crazy, .., Avail...   \n",
       "1           [Ok, lar, ..., Joking, wif, u, oni, ...]   \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  [U, dun, say, so, early, hor, ..., U, c, alrea...   \n",
       "4  [Nah, I, do, n't, think, he, goes, to, usf, ,,...   \n",
       "\n",
       "                                                stem  \\\n",
       "0  [go, until, jurong, point, ,, crazi, .., avail...   \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]   \n",
       "2  [free, entri, in, 2, a, wkli, comp, to, win, f...   \n",
       "3  [u, dun, say, so, earli, hor, ..., u, c, alrea...   \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, ,, ...   \n",
       "\n",
       "                                                 lem  \\\n",
       "0  [go, until, jurong, point, ,, crazi, .., avail...   \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]   \n",
       "2  [free, entri, in, 2, a, wkli, comp, to, win, f...   \n",
       "3  [u, dun, say, so, earli, hor, ..., u, c, alrea...   \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, ,, ...   \n",
       "\n",
       "                                                punc  \\\n",
       "0  [go, until, jurong, point, crazi, .., avail, o...   \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]   \n",
       "2  [free, entri, in, 2, a, wkli, comp, to, win, f...   \n",
       "3  [u, dun, say, so, earli, hor, ..., u, c, alrea...   \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, he,...   \n",
       "\n",
       "                                            stopword  \\\n",
       "0  [go, jurong, point, crazi, .., avail, onli, bu...   \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3  [u, dun, say, earli, hor, ..., u, c, alreadi, ...   \n",
       "4  [nah, n't, think, goe, usf, live, around, though]   \n",
       "\n",
       "                                               ready  \n",
       "0  go jurong point crazi .. avail onli bugi n gre...  \n",
       "1                      ok lar ... joke wif u oni ...  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3        u dun say earli hor ... u c alreadi say ...  \n",
       "4           nah n't think goe usf live around though  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0f7f7",
   "metadata": {},
   "source": [
    "#### Count Vectorizer\n",
    "Now we need to import count vectorizer so that we can count frequency of no. of words present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "10629a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f91a98b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv= CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dfa304",
   "metadata": {},
   "source": [
    "We fitted our ready column data to count vectorizer, this will create a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3fddcf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x7339 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 49125 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=cv.fit_transform(df.ready)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e98fa",
   "metadata": {},
   "source": [
    "Sparse matrix is a matrix containing 0 and 1 values only, here we are converting our matrix to array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d54273a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16dfa3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 7339)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c524345d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '000pe',\n",
       " '008704050406',\n",
       " '0089',\n",
       " '0121',\n",
       " '01223585236',\n",
       " '01223585334',\n",
       " '0125698789',\n",
       " '02']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_feature_names provide the list of all unique words of dataset for which column is created\n",
    "\n",
    "cv.get_feature_names()[:10] # only checking first 10 names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd5162",
   "metadata": {},
   "source": [
    "Defining x and y value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "96939444",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=c.toarray()\n",
    "y=df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf0cd1",
   "metadata": {},
   "source": [
    "Dividing the data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df3a2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64252bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest= train_test_split(x,y,test_size=0.30,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73d4fb",
   "metadata": {},
   "source": [
    "#### IMPORTING CLASSIFICATION ALGO NAIVE BAYES \n",
    "We are using naive bayes multinomial and bernoulli algo and checking which perform better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "01731bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ff6dea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "628ccb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ml.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57f9232c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766746411483254"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ml.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1d7f7307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'ham', 'spam', ..., 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ypred= ml.predict(xtest)\n",
    "#ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "abefb605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix,f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8e5cca99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1423,   25],\n",
       "       [  14,  210]], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion_matrix(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "97bdcf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766746411483254"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy_score(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c06f0261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9150326797385621"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1_score(ytest,ypred,pos_label='spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3997960a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864818024263432"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1_score(ytest,ypred,pos_label='ham')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed41ee80",
   "metadata": {},
   "source": [
    "Fitting model using Bernoulli naive bayes and checking score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4871168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cf113264",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn=BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e4e465b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3d4dcb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9778708133971292"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e45e51bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'spam', ..., 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred1=bn.predict(xtest)\n",
    "ypred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3760ee7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1443,    5],\n",
       "       [  32,  192]], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score,accuracy_score\n",
    "confusion_matrix(ytest,ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "37cb37a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9778708133971292"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a34b4571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9121140142517815"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytest,ypred1,pos_label='spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c9e45064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9873417721518988"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytest,ypred1,pos_label='ham')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5068722",
   "metadata": {},
   "source": [
    "Fitting model using SVM and checking score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "84f76614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a7be98d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "14ba4c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e9cdb6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.979066985645933"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sc.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bdf7109e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'spam', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ypred2=sc.predict(xtest)\n",
    "#ypred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5d14c0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1446,    2],\n",
       "       [  33,  191]], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion_matrix(ytest,ypred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6c41e8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.979066985645933"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy_score(ytest,ypred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "57b7a8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9160671462829736"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1_score(ytest,ypred2,pos_label='spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "262a2f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9880423641954219"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1_score(ytest,ypred2,pos_label='ham')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de62b7",
   "metadata": {},
   "source": [
    "#### OUTCOME ----- NAIVE BAYES AND SVM ARE GIVING SIMILAR SCORE BUT SVM TAKES MORE TIME TO PROCESS THAN NAIVE BAYES, SO WE WILL CONTINUE USING NAIVE BAYES ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "09a9e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= 'SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1adc40ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x7339 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2ad83d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred= cv.transform([data]).toarray()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8c196f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype='<U4')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.predict(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432c0cad",
   "metadata": {},
   "source": [
    "### CONCLUSION- We can see that our model predicted msg as spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d6d03",
   "metadata": {},
   "source": [
    "Lets check our model once again on different data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d5203072",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2= '''You get a lot of unwanted emails, such as subscriptions or promotional offers. A hacker tries to fill up your Inbox so that you can't find important security alerts from websites or services you signed up for with your Gmail account.\n",
    "\n",
    "For example, if a hacker tries to get into your bank account, your bank can notify you by email. But if your Inbox is full of junk mail, you might miss the bank’s alert.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "04902f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You get a lot of unwanted emails, such as subscriptions or promotional offers. A hacker tries to fill up your Inbox so that you can't find important security alerts from websites or services you signed up for with your Gmail account.\\n\\nFor example, if a hacker tries to get into your bank account, your bank can notify you by email. But if your Inbox is full of junk mail, you might miss the bank’s alert.\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f8d15226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x7339 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 28 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform([data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "44560f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1= cv.transform([data2]).toarray()\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a380895e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype='<U4')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.predict(pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23131692",
   "metadata": {},
   "source": [
    "### CONCLUSION- Similarly, We can see that this model predicted msg as ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876fbd2a",
   "metadata": {},
   "source": [
    "                                   THANK YOU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
